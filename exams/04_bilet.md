# Разбор билета 4

---

## **Теория 1: Основные компоненты типовой мобильной робототехнической системы на ROS**

### **Аппаратные компоненты:**

#### **1. Базовые платформы:**
- **Микроконтроллеры** (Arduino, STM32): Низкоуровневый контроль двигателей, чтение энкодеров
- **Одноплатные компьютеры** (Raspberry Pi, NVIDIA Jetson): Средний уровень, обработка сенсоров
- **Промышленные компьютеры** (Intel NUC, промышленные PC): Высокопроизводительные вычисления, запуск ROS

#### **2. Сенсорные системы:**
- **Лидары (LIDAR):**
  - 2D (Hokuyo, RPLIDAR): Для навигации, SLAM
  - 3D (Velodyne, Ouster): Для сложной навигации, восприятия
- **Камеры:**
  - Монохромные/цветные: Для навигации по визуальным маркерам
  - Глубины (RGB-D): Kinect, RealSense, для 3D восприятия
  - Стереопары: Для оценки глубины
- **Инерциальные измерительные модули (IMU):**
  - Акселерометры, гироскопы, магнитометры
  - Для оценки ориентации, компенсации дрейфа одометрии
- **Энкодеры:** На осях колес, для одометрии
- **Ультразвуковые/инфракрасные датчики:** Для обнаружения близких препятствий
- **Тач-сенсоры, бамперы:** Для обнаружения столкновений

#### **3. Актуаторы и приводы:**
- **Мотор-редукторы с энкодерами**
- **Сервоприводы:** Для манипуляторов, камер
- **Шаговые двигатели:** Для точного позиционирования
- **Пневматические/гидравлические системы** (для промышленных роботов)

#### **4. Коммуникация:**
- **Wi-Fi/Ethernet:** Для связи с ROS-мастером
- **CAN, I2C, SPI, UART:** Для связи с периферией
- **Радиомодули** (XBee, LoRa): Для удаленного управления

#### **5. Источники питания:**
- **Литий-ионные/литий-полимерные аккумуляторы**
- **Системы управления питанием (BMS)**
- **Преобразователи напряжения**

### **Программные компоненты (ROS-стек):**

#### **1. Драйверы устройств (Device Drivers):**
- **ros_arduino_bridge:** Связь с Arduino
- **urg_node, hokuyo_node:** Драйверы лидаров
- **libuvc_camera, usb_cam:** Драйверы камер
- **razor_imu_9dof:** Драйвер IMU
- **rosserial:** Протокол для микроконтроллеров

#### **2. Система преобразований координат (TF2):**
- **tf2:** Библиотека преобразований
- **tf2_ros:** ROS-обертка
- **robot_state_publisher:** Публикация трансформ робота

#### **3. Восприятие (Perception):**
- **Роst:** Библиотека для обработки облаков точек
- **OpenCV:** Компьютерное зрение
- **image_pipeline:** Обработка изображений (калибровка, rectification)
- **laser_geometry:** Преобразование LaserScan → PointCloud

#### **4. Навигационный стек (Navigation Stack):**
- **move_base:** Основной узел навигации
- **amcl:** Локализация по карте
- **gmapping/cartographer:** SLAM
- **costmap_2d:** Карты занятости
- **global_planner, local_planner:** Планировщики пути

#### **5. Управление (Control):**
- **ros_control:** Унифицированный интерфейс управления
- **controller_manager:** Менеджер контроллеров
- **joint_state_controller, diff_drive_controller:** Конкретные контроллеры

#### **6. Инструменты разработки и отладки:**
- **RViz:** 3D визуализация
- **rqt:** Графический фреймворк
- **rosbag:** Запись и воспроизведение данных
- **roslaunch:** Запуск множества нод
- **dynamic_reconfigure:** Динамическая настройка параметров

#### **7. Высокоуровневое управление:**
- **SMACH:** State Machine для сложного поведения
- **behavior_tree:** Деревья поведения
- **actionlib:** Серверы действий для длительных операций

#### **8. Безопасность и мониторинг:**
- **diagnostics:** Диагностика системы
- **safety_limiter:** Ограничители для безопасной работы

---

## **Теория 2: Граф видимости (Visibility Graph)**

### **Определение:**
Граф видимости — это граф, вершинами которого являются:
1. Стартовая точка S
2. Целевая точка G
3. **Все вершины полигональных препятствий**

Ребро существует между двумя вершинами, если:
- Отрезок, соединяющий эти вершины, **не пересекает внутренность** ни одного препятствия
- Отрезок может касаться границ препятствий, но не проходить через них

### **Алгоритм построения графа видимости:**

#### **Шаг 1: Представление данных**
- Препятствия: выпуклые или вогнутые полигоны (списки вершин)
- Все вершины нумеруются: V = {v₁, v₂, ..., vₙ} + S + G

#### **Шаг 2: Проверка видимости для каждой пары вершин**
```python
def is_visible(v_i, v_j, obstacles):
    # Проверяем для каждого препятствия
    for obstacle in obstacles:
        # Проверяем каждое ребро препятствия
        for k in range(len(obstacle.vertices)):
            p1 = obstacle.vertices[k]
            p2 = obstacle.vertices[(k+1) % len(obstacle.vertices)]
            
            # Исключаем случаи, когда отрезок совпадает с ребром препятствия
            if (v_i == p1 and v_j == p2) or (v_i == p2 and v_j == p1):
                continue
            
            # Проверяем пересечение отрезка v_i-v_j с ребром p1-p2
            if segments_intersect(v_i, v_j, p1, p2):
                # Если пересекает внутренность ребра -> не видимы
                if not is_endpoint_intersection(v_i, v_j, p1, p2):
                    return False
    
    return True

def segments_intersect(A, B, C, D):
    """Проверка пересечения двух отрезков AB и CD"""
    # Используем ориентированную площадь или векторное произведение
    def orientation(p, q, r):
        val = (q.y - p.y) * (r.x - q.x) - (q.x - p.x) * (r.y - q.y)
        if val == 0: return 0  # коллинеарны
        return 1 if val > 0 else 2  # по часовой или против
    
    o1 = orientation(A, B, C)
    o2 = orientation(A, B, D)
    o3 = orientation(C, D, A)
    o4 = orientation(C, D, B)
    
    # Общий случай пересечения
    if o1 != o2 and o3 != o4:
        return True
    
    # Специальные случаи (коллинеарность)
    # ... (пропускаем для краткости)
    
    return False
```

#### **Шаг 3: Построение графа**
```python
def build_visibility_graph(S, G, obstacles):
    # Собираем все вершины
    all_vertices = [S, G]
    for obstacle in obstacles:
        all_vertices.extend(obstacle.vertices)
    
    # Инициализируем граф
    graph = {v: [] for v in all_vertices}
    
    # Проверяем все пары вершин
    n = len(all_vertices)
    for i in range(n):
        for j in range(i+1, n):
            if is_visible(all_vertices[i], all_vertices[j], obstacles):
                # Добавляем ребро в обе стороны (неориентированный граф)
                distance = euclidean_distance(all_vertices[i], all_vertices[j])
                graph[all_vertices[i]].append((all_vertices[j], distance))
                graph[all_vertices[j]].append((all_vertices[i], distance))
    
    return graph
```

#### **Шаг 4: Поиск пути**
- После построения графа используем алгоритм поиска пути (A*, Dijkstra)
- Кратчайший путь в графе видимости = кратчайший геометрический путь в свободном пространстве

### **Преимущества:**

1. **Гарантированная оптимальность:**
   - Находит **геометрически кратчайший путь** среди всех возможных
   - Глобально оптимальное решение для статической среды

2. **Точность:**
   - Путь проходит точно по границам препятствий
   - Можно получить аналитически точную траекторию

3. **Простота последующей оптимизации:**
   - Полученный путь можно легко сгладить
   - Хорошая основа для постобработки

### **Недостатки:**

1. **Вычислительная сложность:**
   - В худшем случае: O(n³), где n — количество вершин препятствий
   - Каждая пара вершин: O(n) проверок пересечений
   - Неприменимо для большого числа препятствий

2. **Только для полигональных препятствий:**
   - Сложно работать с криволинейными границами
   - Нужна полигональная аппроксимация

3. **Небезопасность пути:**
   - Путь проходит вплотную к углам препятствий
   - Нет запаса безопасности
   - Непригодно для роботов с ненулевыми размерами

4. **Статичность:**
   - Не приспособлен для динамических препятствий
   - Перестроение графа при изменении среды — дорого

5. **Проблема с выпуклыми препятствиями:**
   - Для выпуклых препятствий можно использовать упрощенные алгоритмы
   - Для вогнутых — сложнее

### **Улучшения и модификации:**

#### **1. Reduced Visibility Graph:**
- Включает только "необходимые" вершины
- Уменьшает размер графа

#### **2. Tangent Graph:**
- Ребра только между вершинами, которые видны по касательной
- Еще меньше вершин

#### **3. С учетом размеров робота:**
- "Раздувать" препятствия на радиус робота
- Или строить граф для центра робота с учетом clearance

### **Применение в робототехнике:**
- **Прототипирование:** Для проверки концепций
- **Оффлайн-планирование:** Для заранее известных сред
- **В сочетании с другими методами:** Как начальное приближение
- **Для дронов/манипуляторов:** Где точность важнее скорости

---

## **Задача: Процесс SLAM в ROS**

### **Архитектура SLAM в ROS:**

```
[Датчики] → [Драйверы] → [SLAM алгоритм] → [Карта] → [Локализация]
   ↑            ↑             ↑                ↑           ↑
 Лидар        urg_node      gmapping       map_server     amcl
 Камеры       hokuyo_node   cartographer   nav_msgs       tf
 Одометрия    laser_proc    hector_slam    occupancy_grid
 IMU
```

### **Ключевые пакеты для SLAM:**

#### **1. gmapping (openslam_gmapping + gmapping)**
- **Тип:** Лазерный 2D SLAM на основе фильтра частиц
- **Алгоритм:** Rao-Blackwellized Particle Filter (RBPF)
- **Особенности:**
  - Требует точной одометрии
  - Создает Occupancy Grid Map
  - Хорошо работает в помещениях
- **Запуск:**
  ```bash
  rosrun gmapping slam_gmapping \
    scan:=/laser/scan \
    _xmax:=30 _ymax:=30 _delta:=0.05
  ```

#### **2. cartographer (Google)**
- **Тип:** Графовый 2D/3D SLAM
- **Алгоритм:** Оптимизация графа поз с loop closure
- **Особенности:**
  - Менее чувствителен к ошибкам одометрии
  - Поддерживает многодатчиковую интеграцию
  - Создает submaps, затем глобальную карту
  - Лучше для больших пространств
- **Конфигурация:** Через LUA-скрипты

#### **3. hector_slam**
- **Тип:** Лазерный 2D SLAM без одометрии
- **Алгоритм:** Сопоставление сканов с градиентным спуском
- **Особенности:**
  - Не требует одометрии (использует IMU или scan matching)
  - Быстрый, но может "дрейфовать" в больших помещениях
  - Хорош для платформ с плохой одометрией

#### **4. rtabmap_ros**
- **Тип:** Визуальный и многодатчиковый SLAM
- **Алгоритм:** Appearance-based loop closure
- **Особенности:**
  - Работает с камерами, RGB-D, лидарами
  - Создает 3D карты
  - Эффективное управление памятью

#### **5. ORB_SLAM2/3 (визуальный)**
- **Тип:** Визуальный SLAM на основе особенностей
- **Алгоритм:** ORB-дескрипторы + оптимизация графа
- **Особенности:**
  - Только камеры (моно, стерео, RGB-D)
  - Высокая точность в богатых текстурами средах

### **Ключевые типы сообщений:**

#### **1. sensor_msgs/LaserScan (лидар)**
```yaml
Header header            # Временная метка и фрейм
float32 angle_min        # Начальный угол (рад)
float32 angle_max        # Конечный угол
float32 angle_increment  # Шаг угла
float32 time_increment   # Время между измерениями
float32 scan_time        # Время полного скана
float32 range_min        # Минимальная дальность
float32 range_max        # Максимальная дальность
float32[] ranges         # Измерения дальности
float32[] intensities    # Интенсивности (опционально)
```
**Использование в SLAM:** Основной источник данных о геометрии среды.

#### **2. nav_msgs/Odometry (одометрия)**
```yaml
Header header
string child_frame_id    # Фрейм робота (обычно base_link)
PoseWithCovariance pose  # Поза робота (положение + ориентация)
TwistWithCovariance twist # Скорость (линейная + угловая)
```
**Использование:** Первоначальное предположение о движении (prior для фильтра частиц).

#### **3. sensor_msgs/Imu (инерциальный блок)**
```yaml
Header header
Quaternion orientation   # Ориентация (часто неточная)
float64[9] orientation_covariance
Vector3 angular_velocity # Угловая скорость
float64[9] angular_velocity_covariance
Vector3 linear_acceleration # Линейное ускорение
float64[9] linear_acceleration_covariance
```
**Использование:** Для оценки ориентации, компенсации наклона лидара.

#### **4. nav_msgs/OccupancyGrid (карта)**
```yaml
Header header
nav_msgs/MapMetaData info
int8[] data              # Данные карты (-1=неизвестно, 0-100=вероятность занятости)
```
**Структура MapMetaData:**
```yaml
time map_load_time
float32 resolution       # м/пиксель
uint32 width, height     # размер в пикселях
geometry_msgs/Pose origin # Позиция левого нижнего угла
```

#### **5. geometry_msgs/PoseWithCovariance (поза с ковариацией)**
```yaml
Pose pose
float64[36] covariance   # Матрица 6x6 (x, y, z, roll, pitch, yaw)
```
**Использование:** Оценка позы робота с неопределенностью.

#### **6. tf2_msgs/TFMessage (преобразования координат)**
```yaml
geometry_msgs/TransformStamped[] transforms
```
**Использование:** Для связи всех систем координат (map → odom → base_link → sensor).

### **Типичный процесс запуска SLAM:**

#### **1. Запуск драйверов датчиков:**
```bash
# Лидар
rosrun urg_node urg_node _ip_address:=192.168.0.10

# Камера (если используется визуальный SLAM)
roslaunch usb_cam usb_cam-test.launch

# Одометрия (из энкодеров)
rosrun robot_pose_ekf robot_pose_ekf
```

#### **2. Настройка TF дерева:**
```xml
<!-- В launch-файле -->
<node pkg="tf" type="static_transform_publisher" 
      name="lidar_tf" args="0.2 0 0.3 0 0 0 base_link laser 100"/>
<node pkg="tf" type="static_transform_publisher" 
      name="imu_tf" args="0 0 0.1 0 0 0 base_link imu 100"/>
```

#### **3. Запуск SLAM алгоритма:**
```xml
<!-- gmapping -->
<node pkg="gmapping" type="slam_gmapping" name="slam_gmapping">
  <remap from="scan" to="/laser/scan"/>
  <param name="delta" value="0.05"/>
  <param name="xmax" value="30"/>
  <param name="ymax" value="30"/>
  <param name="maxUrange" value="15.0"/>
  <param name="minimumScore" value="50"/>
</node>

<!-- ИЛИ cartographer -->
<node name="cartographer_node" pkg="cartographer_ros"
      type="cartographer_node" args="
          -configuration_directory $(find my_robot)/config
          -configuration_basename cartographer.lua">
  <remap from="scan" to="/laser/scan"/>
</node>
```

#### **4. Визуализация и управление:**
```bash
# Просмотр карты в RViz
rosrun rviz rviz -d $(find my_robot)/rviz/slam.rviz

# Сохранение карты (после построения)
rosrun map_server map_saver -f ~/map

# Телеоперация для исследования среды
rosrun teleop_twist_keyboard teleop_twist_keyboard.py
```

### **Критические параметры настройки:**

#### **Для gmapping:**
```yaml
particles: 30           # Количество частиц (больше = точнее, но медленнее)
delta: 0.05             # Разрешение карты (м/пиксель)
maxUrange: 8.0          # Максимальный диапазон лидара для карты
minimumScore: 50        # Минимальный score для принятия скана
```

#### **Для cartographer:**
```lua
-- В cartographer.lua
TRAJECTORY_BUILDER_2D.num_accumulated_range_data = 1
POSE_GRAPH.optimize_every_n_nodes = 90
MAP_BUILDER.use_trajectory_builder_2d = true
```

### **Диагностика проблем SLAM:**

1. **Дрейф карты:**
   - Проверить одометрию
   - Увеличить количество частиц (gmapping)
   - Включить loop closure (cartographer)

2. **Дублирование стен:**
   - Проверить калибровку лидара
   - Настроить `minimumScore` (gmapping)

3. **Пустая/неполная карта:**
   - Проверить топик `/scan`
   - Увеличить `maxUrange`
   - Проверить TF преобразования

### **Переход от SLAM к навигации:**
```bash
# 1. Сохраняем карту после SLAM
rosrun map_server map_saver -f ~/my_map

# 2. Запускаем карту для навигации
rosrun map_server map_server ~/my_map.yaml

# 3. Запускаем локализацию (AMCL)
rosrun amcl amcl scan:=/laser/scan

# 4. Запускаем навигацию
roslaunch my_robot_navigation move_base.launch
```

### **Современные тенденции:**
1. **Многодатчиковая интеграция:** Лидар + камеры + IMU
2. **Семантический SLAM:** Не только геометрия, но и семантика объектов
3. **Обученные SLAM:** Нейросетевые подходы
4. **Облачный SLAM:** Распределенная обработка, общие карты
5. **Lifelong SLAM:** Постоянное обновление карты

### **Вывод:**
SLAM в ROS — это **пайплайн от сырых данных датчиков до навигационной карты**, реализованный через стандартные интерфейсы сообщений. Ключ к успеху — правильная калибровка датчиков, настройка TF дерева и выбор алгоритма, подходящего под условия работы робота.