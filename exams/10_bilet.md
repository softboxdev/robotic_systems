
---

## **Теория 1: Тенденции: от автоматизации к автономности. Новые требования к алгоритмам**

**Ключевой сдвиг:**
*   **Автоматизация:** Робот выполняет заранее запрограммированную последовательность действий в **предсказуемой, структурированной среде** (например, конвейерный манипулятор). Управление реактивное, алгоритмы детерминированы.
*   **Автономность:** Робот должен выполнять миссию (поставленную цель) в **динамической, неопределенной, неструктурированной среде**, принимая решения самостоятельно на основе восприятия. Это требует интеллектуального поведения.

### **Новые требования к алгоритмам управления и планирования:**

**1. Устойчивость к неопределенности и динамике среды:**
*   **Планирование:** Алгоритмы должны работать не с идеальной картой, а с **неполными, зашумленными данными** в реальном времени.
*   **Управление:** Контроллеры должны быть **робастными** — компенсировать ошибки локализации, скольжение колес, неточности модели. Широко используются адаптивные и нелинейные методы управления (скользящее управление).

**2. Планирование в условиях частичной наблюдаемости (POMDP):**
*   Робот не знает полного состояния мира. Алгоритмы должны планировать с учетом **вероятностных моделей** (где может быть препятствие? что сделает человек?). Это требует принципиально иных подходов: **POMDP (Partially Observable Markov Decision Process)**.

**3. Переход от глобального к импровизированному (improvisational) планированию:**
*   Невозможно заранее просчитать оптимальный план на всю миссию.
*   **Новый подход:** Гибкая иерархия: **стратегическое целеполагание → тактическое перепланирование → реактивное исполнение**.
*   Активно развиваются методы **многоэтапного (multi-stage) планирования** и **поведенческого (behavior-based) управления**.

**4. Эмерджентность и многоагентность:**
*   Автономные системы часто работают в группах (рои дронов, автоколонны).
*   **Требования:** Алгоритмы **координации, распределенного планирования и коммуникации**. Появляются задачи согласования траекторий, избегания взаимных столкновений, совместного достижения цели (алгоритмы консенсуса, аукционные методы).

**5. Учет семантики и контекста:**
*   Роботу недостаточно видеть "препятствие". Нужно понимать: *это дверь (можно открыть), это человек (уступи дорогу), это газон (можно проехать)*.
*   **Требование:** Интеграция алгоритмов **компьютерного зрения, семантической сегментации и NLP** в контур управления для принятия осмысленных решений.

**6. Обучение с подкреплением (RL) и имитационное обучение:**
*   Закодировать все возможные сценарии для сложной среды невозможно.
*   **Тренд:** Робот **учится на данных и взаимодействии** с миром. Алгоритмы RL позволяют находить стратегии управления, оптимальные для сложных, нелинейных задач.
*   **Вызов:** Требуются огромные вычислительные ресурсы и методы обеспечения безопасности (Safe RL).

**7. Безопасность и объяснимость (Safety & Explainability):**
*   Критически важное требование. Алгоритмы должны иметь **гарантии безопасности** (например, использование **барьерных функций** в управлении).
*   Их решения должны быть **интерпретируемы человеком** для доверия и отладки. Это приводит к развитию **гибридных систем**: "мозг" на RL + "рефлексы" на классических детерминированных контроллерах.

**Итог:** Эволюция от автоматизации к автономности превращает робота из исполнителя программы в **агента, способного к целеполаганию, обучению и адаптации в открытом мире**. Это требует перехода от классической теории управления к методам **искусственного интеллекта, теории вероятностей и машинного обучения**.

---

## **Теория 2: Алгоритм Potential Fields (поля потенциалов)**

**Идея:** Представить среду для робота (точки) как пространство, на которое действуют "силы":
*   **Цель** создает **аттрактивное поле** (притягивает).
*   **Препятствия** создают **репульсивное поле** (отталкивают).
Робот движется как частица в этом суммарном поле по направлению антиградиента (в сторону уменьшения потенциала).

### **Алгоритм построения траектории:**

1.  **Задаем целевой потенциал `U_att(q)`:** Чаще всего — квадратичный колодец.
    *   `U_att(q) = 0.5 * k_att * ρ_goal(q)²`, где
    *   `k_att` — коэффициент притяжения,
    *   `ρ_goal(q)` — расстояние от текущей позиции робота `q` до цели `q_goal`.
    *   **Сила притяжения:** `F_att(q) = -∇U_att(q) = -k_att * (q - q_goal)`.

2.  **Задаем репульсивный потенциал `U_rep(q)` от препятствий:** Действует только вблизи препятствия.
    *   `U_rep(q) = { 0.5 * k_rep * (1/ρ(q) - 1/ρ₀)², если ρ(q) ≤ ρ₀; 0, если ρ(q) > ρ₀ }`, где
    *   `k_rep` — коэффициент отталкивания,
    *   `ρ(q)` — расстояние от `q` до ближайшего препятствия,
    *   `ρ₀` — радиус влияния препятствия (за его пределами поле = 0).
    *   **Сила отталкивания:** `F_rep(q) = -∇U_rep(q)`.

3.  **Вычисляем суммарное поле и силу:**
    *   `U_total(q) = U_att(q) + Σ U_rep_i(q)` (сумма по всем препятствиям).
    *   `F_total(q) = F_att(q) + Σ F_rep_i(q)`.

4.  **Генерация траектории (итеративно):**
    *   Начальная позиция: `q = q_start`.
    *   **Шаг планирования:** `q_next = q + η * (F_total(q) / ||F_total(q)||)`.
        *   `η` — размер шага (коэффициент).
        *   Сила нормируется, чтобы шаг был управляемым.
    *   Повторяем, пока `q` не окажется достаточно близко к `q_goal` или не будет достигнуто max число итераций.

### **Достоинства:**
*   **Простота и вычислительная эффективность:** Легко реализуется, работает в реальном времени.
*   **Реактивность:** Мгновенно реагирует на появление новых препятствий, так как поле пересчитывается на каждом шаге. Идеален для **локального планирования**.
*   **Плавность:** Генерирует плавные траектории, если параметры подобраны правильно.
*   **Естественность:** Концептуально понятная физическая аналогия.

### **Фундаментальные недостатки:**

**1. Локальные минимумы — ГЛАВНАЯ ПРОБЛЕМА:**
*   В некоторых конфигурациях аттрактивные и репульсивные силы уравновешиваются, и `F_total(q) = 0`, хотя цель не достигнута.
*   **Типичные сценарии:**
    *   Препятствие прямо перед целью. Робот "застревает" на равном расстоянии.
    *   Симметричные препятствия, образующие "коридор".
    *   Замкнутые пространства (например, П-образное препятствие).
*   **Следствие:** Алгоритм **не гарантирует достижения цели**.

**2. Колебания в узких проходах:**
*   При движении по узкому коридору репульсивные силы от стен могут начать "качать" робота из стороны в сторону.

**3. Проблема "недостижимой цели":**
*   Если цель находится внутри самого препятствия (или в зоне с `ρ(q)=0`), репульсивная сила стремится к бесконечности, и робот никогда не достигнет цели.

**4. Зависимость от параметров (`k_att`, `k_rep`, `ρ₀`):**
*   Плохой подбор параметров может сделать робота либо слишком "трусливым" (сильно отталкивается, не может войти в узкий проход), либо слишком "агрессивным" (задевает углы).

**Методы борьбы с локальными минимумами:**
*   Добавление **шума** (случайных возмущений) в силу.
*   Использование **навигационных функций** (специально сконструированное поле без минимумов, но для сложных сред построить сложно).
*   **Гибридные подходы:** Potential Fields + глобальный планировщик (A*). Поле используется для локального отклонения, а при застревании активируется перепланирование глобального пути.

---

## **Задача: DFS и BFS на связном графе**

**Дан граф:**
```
    A
   / \
  B   C
 / \   \
D   E - F
```
*Вершины: {A, B, C, D, E, F}*
*Ребра: (A-B), (A-C), (B-D), (B-E), (C-F), (E-F)*
*Начальная вершина: **A***

### **1. Поиск в глубину (Depth-First Search, DFS)**
**Принцип:** Идти "вглубь" графа насколько возможно, затем отступать (backtrack). Используется **стек** (явный или неявный в рекурсии).

**Порядок обхода (предполагая, что соседей рассматриваем в алфавитном порядке):**

1.  Стартуем с **A**. Помечаем как посещенную.
2.  Из A идем в первую непосещенную соседку — **B**.
3.  Из B идем в первую непосещенную соседку — **D**.
4.  У D нет непосещенных соседей. Возвращаемся (backtrack) к B.
5.  Из B идем в следующую непосещенную соседку — **E**.
6.  Из E идем в непосещенную соседку — **F**.
7.  Из F идем в непосещенную соседку — **C** (по ребру F-C).
8.  У C нет непосещенных соседей. Возвращаемся к F → к E → к B → к A. Обход завершен.

**Порядок посещения вершин:**
```
A → B → D → E → F → C
```
*(Последовательность добавления вершин в порядок обхода)*.

**Дерево обхода DFS:**
```
      A
     /
    B
   / \
  D   E
       \
        F
         \
          C
```

### **2. Поиск в ширину (Breadth-First Search, BFS)**
**Принцип:** Сначала посещаем всех соседей начальной вершины, затем соседей соседей и т.д. Используется **очередь (FIFO)**.

**Порядок обхода (соседей в алфавитном порядке):**

1.  Стартуем с **A**. Кладем в очередь `Q = [A]`.
2.  Извлекаем **A** из очереди. Посещаем ее соседей: **B, C**. Кладем их в очередь: `Q = [B, C]` (порядок: B, потом C).
3.  Извлекаем **B** из очереди. Ее непосещенные соседи: **D, E**. Кладем в очередь: `Q = [C, D, E]`.
4.  Извлекаем **C** из очереди. Ее непосещенный сосед: **F**. Кладем в очередь: `Q = [D, E, F]`.
5.  Извлекаем **D** из очереди. Непосещенных соседей нет.
6.  Извлекаем **E** из очереди. Ее сосед F уже посещен (или в очереди). Новых не добавляем.
7.  Извлекаем **F** из очереди. Все соседи посещены. Очередь пуста.

**Порядок посещения вершин:**
```
A → B → C → D → E → F
```
*(Вершины посещаются по уровням удаленности от A)*.

**Дерево обхода BFS:**
```
      A
     / \
    B   C
   / \   \
  D   E   F
```
*(Заметим, что ребро E-F не используется в дереве BFS, так как F уже была достигнута через C).*

**Итог:**
*   **DFS:** `A, B, D, E, F, C`
*   **BFS:** `A, B, C, D, E, F`